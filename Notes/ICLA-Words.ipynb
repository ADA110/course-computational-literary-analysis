{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words, Tokens, Stems, Lemmas\n",
    "\n",
    "## and the NLTK\n",
    "\n",
    "Natural Language (processing) ToolKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to importing the NLTK, we also need to make sure to download the language models for English. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('book')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, make sure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jon/Code/course-computational-literary-analysis\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mHomework\u001b[0m/  \u001b[01;34mHW1\u001b[0m/  LICENSE  moonstone.md  \u001b[01;34mNotes\u001b[0m/  README.md\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "moonstoneRaw = open('moonstone.md', encoding=\"UTF-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "moonstoneParts = moonstoneRaw.split('%%%%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(moonstoneParts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "betteredge = moonstoneParts[1]\n",
    "clack = moonstoneParts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "### Chapter I\n",
      "\n",
      "I am indebted to my dear parents (both now in heaven) for having had\n",
      "habits of order and regularity instilled into me at a very early age.\n",
      "\n",
      "In that happy bygone time, I was taught to keep my hair tidy at all\n",
      "hours of the day and night, and to fold up every article of my clothing\n",
      "carefully, in the same order, on the same chair, in the same place at\n",
      "the foot of the bed, before retiring to rest. An entry of the day’s\n",
      "events in my little diary invariably preceded the folding up. Th\n"
     ]
    }
   ],
   "source": [
    "print(clack[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSentence = \"\"\"\n",
    "I am indebted to my dear parents (both now in heaven) \n",
    "for having had habits of order and regularity \n",
    "instilled into me at a very early age.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I am indebted to my dear parents (both now in heaven) \n",
      "for having had habits of order and regularity \n",
      "instilled into me at a very early age.\n"
     ]
    }
   ],
   "source": [
    "print(testSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.word_tokenize(testSentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'indebted',\n",
       " 'to',\n",
       " 'my',\n",
       " 'dear',\n",
       " 'parents',\n",
       " '(',\n",
       " 'both',\n",
       " 'now',\n",
       " 'in',\n",
       " 'heaven',\n",
       " ')',\n",
       " 'for',\n",
       " 'having',\n",
       " 'had',\n",
       " 'habits',\n",
       " 'of',\n",
       " 'order',\n",
       " 'and',\n",
       " 'regularity',\n",
       " 'instilled',\n",
       " 'into',\n",
       " 'me',\n",
       " 'at',\n",
       " 'a',\n",
       " 'very',\n",
       " 'early',\n",
       " 'age',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.wordpunct_tokenize(testSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An',\n",
       " 'entry',\n",
       " 'of',\n",
       " 'the',\n",
       " 'day',\n",
       " '’',\n",
       " 's',\n",
       " 'events',\n",
       " 'in',\n",
       " 'my',\n",
       " 'little',\n",
       " 'diary',\n",
       " 'invariably',\n",
       " 'preceded',\n",
       " 'the',\n",
       " 'folding',\n",
       " 'up',\n",
       " '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(\"An entry of the day’s events in my little diary invariably preceded the folding up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'ca', \"n't\", 'believe', 'this', '!']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(\"I can't believe this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "believ\n",
      "believ\n",
      "believ\n"
     ]
    }
   ],
   "source": [
    "for word in [\"believe\", \"belief\", \"believing\"]:\n",
    "    print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'believ'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"believe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'believe'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"believe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "believe\n",
      "belief\n",
      "believing\n"
     ]
    }
   ],
   "source": [
    "for word in [\"believe\", \"belief\", \"believing\"]:\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n",
      "happier\n",
      "happiest\n"
     ]
    }
   ],
   "source": [
    "for word in [\"happy\", \"happier\", \"happiest\"]:\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "went\n",
      "going\n",
      "gone\n"
     ]
    }
   ],
   "source": [
    "for word in [\"go\", \"went\", \"going\", \"gone\"]:\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump\n",
      "jumping\n",
      "jump\n"
     ]
    }
   ],
   "source": [
    "for word in [\"jumps\", \"jumping\", \"jump\"]:\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTokens = nltk.word_tokenize(testSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "am\n",
      "indebt\n",
      "to\n",
      "my\n",
      "dear\n",
      "par\n",
      "(\n",
      "both\n",
      "now\n",
      "in\n",
      "heav\n",
      ")\n",
      "for\n",
      "hav\n",
      "had\n",
      "habit\n",
      "of\n",
      "ord\n",
      "and\n",
      "regul\n",
      "instil\n",
      "into\n",
      "me\n",
      "at\n",
      "a\n",
      "very\n",
      "ear\n",
      "ag\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word in testTokens: \n",
    "    print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clackTokens = nltk.word_tokenize(clack)\n",
    "betteredgeTokens = nltk.word_tokenize(betteredge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36247, 94899)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clackTokens), len(betteredgeTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clackStems = []\n",
    "for word in clackTokens: \n",
    "    stem = stemmer.stem(word)\n",
    "    clackStems.append(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "betteredgeStems = []\n",
    "for word in betteredgeTokens: \n",
    "    stem = stemmer.stem(word)\n",
    "    betteredgeStems.append(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clackStemsDict = {}\n",
    "for stem in clackStems:\n",
    "    # If our stem is not already in the dictionary, \n",
    "    # it has a frequency of one. \n",
    "    if stem not in clackStemsDict: \n",
    "        clackStemsDict[stem] = 1\n",
    "    else: \n",
    "        clackStemsDict[stem] = clackStemsDict[stem] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "betteredgeStemsDict = {}\n",
    "for stem in betteredgeStems:\n",
    "    # If our stem is not already in the dictionary, \n",
    "    # it has a frequency of one. \n",
    "    if stem not in betteredgeStemsDict: \n",
    "        betteredgeStemsDict[stem] = 1\n",
    "    else: \n",
    "        betteredgeStemsDict[stem] = betteredgeStemsDict[stem] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36247, 94899)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clackTokens), len(betteredgeTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0068419455403205785\n",
      "0.003530068809997998\n"
     ]
    }
   ],
   "source": [
    "print(clackStemsDict['!']/len(clackTokens)) \n",
    "print(betteredgeStemsDict['!']/len(betteredgeTokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#': 69,\n",
       " 'chapt': 25,\n",
       " 'i': 2044,\n",
       " 'in': 1677,\n",
       " 'the': 4838,\n",
       " 'first': 128,\n",
       " 'part': 47,\n",
       " 'of': 2130,\n",
       " 'robinson': 22,\n",
       " 'cruso': 24,\n",
       " ',': 6281,\n",
       " 'at': 573,\n",
       " 'pag': 7,\n",
       " 'on': 1118,\n",
       " 'hundr': 15,\n",
       " 'and': 1931,\n",
       " 'twenty-nine': 1,\n",
       " 'you': 807,\n",
       " 'wil': 182,\n",
       " 'find': 61,\n",
       " 'it': 1023,\n",
       " 'thu': 4,\n",
       " 'writ': 41,\n",
       " ':': 74,\n",
       " '“': 1212,\n",
       " 'now': 156,\n",
       " 'saw': 84,\n",
       " 'though': 22,\n",
       " 'too': 57,\n",
       " 'lat': 48,\n",
       " 'fol': 3,\n",
       " 'begin': 33,\n",
       " 'a': 1496,\n",
       " 'work': 40,\n",
       " 'bef': 164,\n",
       " 'we': 258,\n",
       " 'count': 8,\n",
       " 'cost': 4,\n",
       " 'judg': 18,\n",
       " 'right': 65,\n",
       " 'our': 148,\n",
       " 'own': 195,\n",
       " 'strength': 6,\n",
       " 'to': 2666,\n",
       " 'go': 90,\n",
       " 'through': 55,\n",
       " 'with': 638,\n",
       " 'it.': 21,\n",
       " '”': 1212,\n",
       " 'yesterday': 8,\n",
       " 'op': 48,\n",
       " 'my': 1042,\n",
       " 'that': 1069,\n",
       " 'plac': 102,\n",
       " '.': 3470,\n",
       " 'thi': 377,\n",
       " 'morn': 59,\n",
       " '(': 212,\n",
       " 'may': 81,\n",
       " 'twenty-first': 5,\n",
       " 'eighteen': 3,\n",
       " 'fifty': 7,\n",
       " ')': 212,\n",
       " 'cam': 125,\n",
       " 'lady': 344,\n",
       " '’': 1191,\n",
       " 's': 705,\n",
       " 'nephew': 5,\n",
       " 'mr.': 609,\n",
       " 'franklin': 387,\n",
       " 'blak': 55,\n",
       " 'held': 20,\n",
       " 'short': 20,\n",
       " 'convers': 12,\n",
       " 'me': 625,\n",
       " 'as': 826,\n",
       " 'follow': 74,\n",
       " '–': 2,\n",
       " 'betteredg': 120,\n",
       " 'say': 317,\n",
       " 'hav': 596,\n",
       " 'been': 215,\n",
       " 'lawy': 9,\n",
       " 'about': 199,\n",
       " 'som': 91,\n",
       " 'famy': 46,\n",
       " 'mat': 84,\n",
       " ';': 420,\n",
       " 'among': 44,\n",
       " 'oth': 128,\n",
       " 'thing': 137,\n",
       " 'talk': 45,\n",
       " 'loss': 26,\n",
       " 'ind': 101,\n",
       " 'diamond': 158,\n",
       " 'aunt': 28,\n",
       " 'hous': 177,\n",
       " 'yorkshir': 6,\n",
       " 'two': 124,\n",
       " 'year': 35,\n",
       " 'sint': 39,\n",
       " 'bruff': 8,\n",
       " 'think': 80,\n",
       " 'whol': 23,\n",
       " 'story': 30,\n",
       " 'ought': 16,\n",
       " 'interest': 44,\n",
       " 'tru': 43,\n",
       " 'be': 354,\n",
       " 'record': 4,\n",
       " 'writing–and': 1,\n",
       " 'soon': 28,\n",
       " 'better.': 1,\n",
       " 'not': 348,\n",
       " 'perceiv': 1,\n",
       " 'his': 566,\n",
       " 'drift': 16,\n",
       " 'yet': 27,\n",
       " 'alway': 27,\n",
       " 'desir': 12,\n",
       " 'for': 576,\n",
       " 'sak': 12,\n",
       " 'peac': 3,\n",
       " 'quiet': 33,\n",
       " 'sid': 89,\n",
       " 'said': 383,\n",
       " 'thought': 71,\n",
       " 'so': 112,\n",
       " 'went': 154,\n",
       " 'he': 818,\n",
       " 'charact': 39,\n",
       " 'innoc': 17,\n",
       " 'peopl': 53,\n",
       " 'suff': 7,\n",
       " 'und': 51,\n",
       " 'susp': 24,\n",
       " 'already–as': 1,\n",
       " 'know': 134,\n",
       " 'mem': 9,\n",
       " 'hereaft': 1,\n",
       " 'want': 84,\n",
       " 'fact': 11,\n",
       " 'which': 269,\n",
       " 'thos': 65,\n",
       " 'who': 128,\n",
       " 'com': 134,\n",
       " 'aft': 147,\n",
       " 'us': 201,\n",
       " 'can': 137,\n",
       " 'ap': 10,\n",
       " 'ther': 238,\n",
       " 'no': 200,\n",
       " 'doubt': 39,\n",
       " 'strange': 23,\n",
       " 'told': 64,\n",
       " 'togeth': 51,\n",
       " 'hit': 11,\n",
       " 'way': 212,\n",
       " 'tel': 113,\n",
       " 'very': 112,\n",
       " 'satisfact': 5,\n",
       " 'both': 36,\n",
       " 'them': 216,\n",
       " 'but': 220,\n",
       " 'fail': 16,\n",
       " 'see': 150,\n",
       " 'what': 342,\n",
       " 'myself': 95,\n",
       " 'had': 803,\n",
       " 'do': 169,\n",
       " 'far': 44,\n",
       " 'certain': 44,\n",
       " 'ev': 149,\n",
       " 'rel': 20,\n",
       " 'process': 34,\n",
       " 'person': 84,\n",
       " 'concern': 11,\n",
       " 'ar': 168,\n",
       " 'cap': 4,\n",
       " 'start': 28,\n",
       " 'from': 279,\n",
       " 'thes': 44,\n",
       " 'plain': 52,\n",
       " 'ide': 10,\n",
       " 'is': 373,\n",
       " 'should': 70,\n",
       " 'al': 309,\n",
       " 'moonston': 65,\n",
       " 'turn–as': 1,\n",
       " 'expery': 43,\n",
       " 'extend': 2,\n",
       " 'farth': 1,\n",
       " 'must': 95,\n",
       " 'by': 333,\n",
       " 'show': 48,\n",
       " 'how': 102,\n",
       " 'fel': 13,\n",
       " 'into': 181,\n",
       " 'hand': 130,\n",
       " 'unc': 8,\n",
       " 'herncastl': 10,\n",
       " 'when': 321,\n",
       " 'was': 958,\n",
       " 'serv': 127,\n",
       " 'pref': 4,\n",
       " 'nar': 5,\n",
       " 'already': 37,\n",
       " 'got': 127,\n",
       " 'form': 18,\n",
       " 'an': 178,\n",
       " 'old': 63,\n",
       " 'pap': 18,\n",
       " 'necess': 12,\n",
       " 'particul': 27,\n",
       " 'auth': 8,\n",
       " 'eye-witness': 1,\n",
       " 'next': 89,\n",
       " 'found': 81,\n",
       " 'ago': 3,\n",
       " 'lost': 30,\n",
       " 'littl': 133,\n",
       " 'mor': 156,\n",
       " 'than': 126,\n",
       " 'twelv': 5,\n",
       " 'hour': 49,\n",
       " 'afterward': 15,\n",
       " 'nobody': 16,\n",
       " 'much': 69,\n",
       " 'tim': 224,\n",
       " 'tak': 175,\n",
       " 'pen': 5,\n",
       " 'story.': 1,\n",
       " 'term': 8,\n",
       " 'inform': 44,\n",
       " 'if': 304,\n",
       " 'cury': 12,\n",
       " 'cours': 35,\n",
       " 'took': 89,\n",
       " 'circumst': 26,\n",
       " 'beg': 57,\n",
       " 'did': 86,\n",
       " 'would': 119,\n",
       " 'prob': 10,\n",
       " 'don': 163,\n",
       " 'modest': 3,\n",
       " 'decl': 17,\n",
       " 'quit': 60,\n",
       " 'uneq': 1,\n",
       " 'task': 1,\n",
       " 'impos': 2,\n",
       " 'upon': 30,\n",
       " 'me–and': 3,\n",
       " 'priv': 43,\n",
       " 'felt': 32,\n",
       " 'clev': 11,\n",
       " 'enough': 74,\n",
       " 'perform': 10,\n",
       " 'gav': 37,\n",
       " 'abl': 9,\n",
       " 'fair': 9,\n",
       " 'chant': 33,\n",
       " 'imagin': 8,\n",
       " 'seen': 57,\n",
       " 'senty': 2,\n",
       " 'fac': 84,\n",
       " 'declin': 10,\n",
       " 'believ': 43,\n",
       " 'modesty': 2,\n",
       " 'insist': 11,\n",
       " 'giv': 85,\n",
       " 'pass': 62,\n",
       " 'left': 96,\n",
       " 'back': 162,\n",
       " 'turn': 117,\n",
       " 'desk': 1,\n",
       " 'sat': 24,\n",
       " 'helpless': 6,\n",
       " 'spit': 23,\n",
       " 'quot': 3,\n",
       " 'above–namely': 1,\n",
       " 'pleas': 56,\n",
       " 'rememb': 35,\n",
       " 'book': 16,\n",
       " 'accid': 14,\n",
       " 'bit': 17,\n",
       " 'day': 74,\n",
       " 'rash': 2,\n",
       " 'undertook': 3,\n",
       " 'busy': 41,\n",
       " 'allow': 14,\n",
       " 'ask–if': 1,\n",
       " 'isn': 22,\n",
       " 't': 309,\n",
       " 'prophecy': 3,\n",
       " '?': 411,\n",
       " 'am': 123,\n",
       " 'superst': 1,\n",
       " 'read': 20,\n",
       " 'heap': 5,\n",
       " 'scholar': 1,\n",
       " 'seventy': 2,\n",
       " 'possess': 37,\n",
       " 'act': 39,\n",
       " 'leg': 23,\n",
       " 'correspond': 2,\n",
       " 'ign': 3,\n",
       " 'man': 158,\n",
       " 'express': 18,\n",
       " 'opin': 37,\n",
       " 'such': 57,\n",
       " 'nev': 73,\n",
       " 'again': 144,\n",
       " 'tri': 40,\n",
       " 'years–generally': 1,\n",
       " 'combin': 1,\n",
       " 'pip': 15,\n",
       " 'tobacco–and': 1,\n",
       " 'friend': 38,\n",
       " 'nee': 16,\n",
       " 'mort': 11,\n",
       " 'lif': 65,\n",
       " 'spirit': 23,\n",
       " 'bad–robinson': 1,\n",
       " 'advice–robinson': 1,\n",
       " 'past': 11,\n",
       " 'wif': 12,\n",
       " 'plagu': 1,\n",
       " 'pres': 95,\n",
       " 'drop': 25,\n",
       " 'much–robinson': 1,\n",
       " 'worn': 6,\n",
       " 'out': 340,\n",
       " 'six': 10,\n",
       " 'stout': 1,\n",
       " 'hard': 42,\n",
       " 'last': 106,\n",
       " 'birthday': 37,\n",
       " 'she': 617,\n",
       " 'seven': 2,\n",
       " 'put': 130,\n",
       " 'pric': 4,\n",
       " 'four': 15,\n",
       " 'shil': 4,\n",
       " 'sixp': 5,\n",
       " 'bound': 12,\n",
       " 'blu': 1,\n",
       " 'pict': 5,\n",
       " 'bargain': 2,\n",
       " 'stil': 62,\n",
       " 'look': 238,\n",
       " 'lik': 128,\n",
       " 'diamond–does': 1,\n",
       " 'seem': 62,\n",
       " 'wand': 8,\n",
       " 'off': 133,\n",
       " 'search': 17,\n",
       " 'lord': 20,\n",
       " 'wher': 67,\n",
       " 'new': 61,\n",
       " 'sheet': 2,\n",
       " 'ov': 97,\n",
       " 'best': 34,\n",
       " 'respect': 38,\n",
       " 'ii': 2,\n",
       " 'spok': 40,\n",
       " 'lin': 19,\n",
       " 'or': 174,\n",
       " 'could': 137,\n",
       " 'mad': 104,\n",
       " 'daught': 80,\n",
       " 'ex': 7,\n",
       " 'pain': 10,\n",
       " 'travail': 1,\n",
       " 'produc': 16,\n",
       " 'her': 946,\n",
       " 'world': 26,\n",
       " 'consequ': 12,\n",
       " 'pretty': 25,\n",
       " 'sur': 24,\n",
       " 'let': 131,\n",
       " 'job': 5,\n",
       " 'min': 23,\n",
       " 'real': 37,\n",
       " 'comfort': 23,\n",
       " 'anyth': 48,\n",
       " 'fash': 6,\n",
       " 'heard': 83,\n",
       " 'three': 58,\n",
       " 'beauty': 20,\n",
       " 'miss': 260,\n",
       " 'adelaid': 1,\n",
       " 'carolin': 2,\n",
       " 'julia–this': 1,\n",
       " 'being': 102,\n",
       " 'youngest': 2,\n",
       " 'sist': 22,\n",
       " 'opportun': 14,\n",
       " 'shal': 59,\n",
       " 'their': 135,\n",
       " 'fath': 67,\n",
       " 'thank': 26,\n",
       " 'god': 20,\n",
       " 'noth': 98,\n",
       " 'him': 383,\n",
       " 'longest': 1,\n",
       " 'tongu': 22,\n",
       " 'shortest': 3,\n",
       " 'temp': 31,\n",
       " 'any': 131,\n",
       " 'high': 28,\n",
       " 'low': 28,\n",
       " 'met': 29,\n",
       " '–i': 3,\n",
       " 'page-boy': 2,\n",
       " 'wait': 73,\n",
       " 'hono': 26,\n",
       " 'young': 84,\n",
       " 'ag': 13,\n",
       " 'fifteen': 1,\n",
       " 'liv': 46,\n",
       " 'til': 39,\n",
       " 'jul': 5,\n",
       " 'marry': 14,\n",
       " 'sir': 100,\n",
       " 'john': 15,\n",
       " 'verind': 73,\n",
       " 'excel': 5,\n",
       " 'somebody': 12,\n",
       " 'between': 66,\n",
       " 'ourselv': 5,\n",
       " 'throve': 1,\n",
       " 'grew': 2,\n",
       " 'fat': 8,\n",
       " 'happy': 11,\n",
       " 'died': 13,\n",
       " 'easy': 22,\n",
       " 'dat': 12,\n",
       " 'church': 2,\n",
       " 'reliev': 22,\n",
       " 'brea': 13,\n",
       " 'clos': 31,\n",
       " 'ey': 75,\n",
       " 'omit': 2,\n",
       " 'stat': 59,\n",
       " 'brid': 2,\n",
       " 'husband': 7,\n",
       " 'land': 7,\n",
       " 'down': 87,\n",
       " 'without': 71,\n",
       " 'gabriel': 12,\n",
       " 'betteredge.': 6,\n",
       " 'either.': 1,\n",
       " 'her–and': 2,\n",
       " 'long': 63,\n",
       " 'mistress': 72,\n",
       " 'wer': 155,\n",
       " 'out-of-door': 3,\n",
       " 'farm': 4,\n",
       " 'too–with': 1,\n",
       " 'reason': 52,\n",
       " 'smal': 14,\n",
       " 'son': 9,\n",
       " 'bailiff': 6,\n",
       " 'promot': 2,\n",
       " 'accord': 17,\n",
       " 'monday': 10,\n",
       " 'might': 101,\n",
       " 'yo': 276,\n",
       " 'stupid': 4,\n",
       " 'pend': 2,\n",
       " 'lib': 4,\n",
       " 'place.': 2,\n",
       " 'tuesday': 3,\n",
       " 'has': 140,\n",
       " 'hear': 70,\n",
       " 'mis': 20,\n",
       " 'exampl': 10,\n",
       " 'cont': 13,\n",
       " 'warn': 17,\n",
       " 'enco': 5,\n",
       " 'meantim': 5,\n",
       " 'wel': 78,\n",
       " 'clov': 1,\n",
       " 'posit': 13,\n",
       " 'trust': 12,\n",
       " 'cot': 14,\n",
       " 'round': 58,\n",
       " 'est': 6,\n",
       " 'occupy': 10,\n",
       " 'account': 25,\n",
       " 'afternoon': 17,\n",
       " 'evening–what': 1,\n",
       " 'poss': 26,\n",
       " 'mak': 118,\n",
       " 'adam': 2,\n",
       " 'alon': 30,\n",
       " 'gard': 32,\n",
       " 'ed': 2,\n",
       " 'blam': 6,\n",
       " 'wom': 98,\n",
       " 'fix': 10,\n",
       " 'kept': 25,\n",
       " 'nam': 40,\n",
       " 'selin': 8,\n",
       " 'goby': 4,\n",
       " 'agr': 6,\n",
       " 'william': 1,\n",
       " 'cobbet': 1,\n",
       " 'pick': 11,\n",
       " 'chew': 1,\n",
       " 'food': 2,\n",
       " 'set': 58,\n",
       " 'foot': 9,\n",
       " 'firm': 16,\n",
       " 'ground': 18,\n",
       " 'walk': 70,\n",
       " 're': 8,\n",
       " 'anoth': 64,\n",
       " 'likew': 1,\n",
       " 'entir': 9,\n",
       " 'discov': 42,\n",
       " 'singl': 5,\n",
       " 'pay': 10,\n",
       " 'week': 17,\n",
       " 'board': 6,\n",
       " 'couldn': 22,\n",
       " 'charg': 12,\n",
       " 'point': 52,\n",
       " 'view': 48,\n",
       " 'economy–with': 1,\n",
       " 'dash': 4,\n",
       " 'lov': 31,\n",
       " 'duty': 12,\n",
       " 'just': 90,\n",
       " 'mind': 116,\n",
       " 'cheap': 6,\n",
       " 'keep': 55,\n",
       " 'her.': 4,\n",
       " 'burst': 18,\n",
       " 'laugh': 9,\n",
       " 'didn': 35,\n",
       " 'most': 58,\n",
       " 'shock': 5,\n",
       " 'at–my': 1,\n",
       " 'langu': 17,\n",
       " 'principl': 6,\n",
       " 'jok': 11,\n",
       " 'tickl': 2,\n",
       " 'suppos': 39,\n",
       " 'sort': 30,\n",
       " 'unless': 7,\n",
       " 'qual': 6,\n",
       " 'understand': 38,\n",
       " 'fre': 9,\n",
       " '!': 335,\n",
       " 'ask': 168,\n",
       " 'ye': 37,\n",
       " 'drew': 8,\n",
       " 'near': 28,\n",
       " 'coat': 11,\n",
       " 'ceremony': 3,\n",
       " 'misg': 1,\n",
       " 'comp': 8,\n",
       " 'men': 27,\n",
       " 'they': 207,\n",
       " 'whil': 31,\n",
       " 'situ': 6,\n",
       " 'acknowledg': 14,\n",
       " 'hap': 57,\n",
       " 'wish': 36,\n",
       " 'themselv': 24,\n",
       " 'trifl': 10,\n",
       " 'furth': 22,\n",
       " 'ros': 46,\n",
       " 'up': 209,\n",
       " 'get': 80,\n",
       " 'expect': 38,\n",
       " 'compens': 1,\n",
       " 'law': 9,\n",
       " 'england': 24,\n",
       " 'obedy': 3,\n",
       " 'car': 24,\n",
       " 'feather-bed': 1,\n",
       " 'nevertheless': 3,\n",
       " 'true–sh': 1,\n",
       " 'fool': 14,\n",
       " 'refus': 19,\n",
       " 'rest': 45,\n",
       " 'coupl': 12,\n",
       " 'half-a-dozen': 1,\n",
       " 'mot': 11,\n",
       " 'up-stairs': 19,\n",
       " 'fiv': 8,\n",
       " 'misunderstand': 1,\n",
       " 'stair': 4,\n",
       " 'all-wise': 1,\n",
       " 'provid': 10,\n",
       " 'each': 25,\n",
       " 'girl': 117,\n",
       " 'penelop': 122,\n",
       " 'child': 16,\n",
       " 'rachel': 208,\n",
       " 'poor': 56,\n",
       " 'purpos': 19,\n",
       " 'requir': 6,\n",
       " 'good': 101,\n",
       " 'sent': 43,\n",
       " 'school': 2,\n",
       " 'taught': 3,\n",
       " 'sharp': 9,\n",
       " 'maid': 16,\n",
       " 'christmas': 1,\n",
       " '1847': 1,\n",
       " 'chang': 27,\n",
       " 'invit': 8,\n",
       " 'herself': 61,\n",
       " 'cup': 3,\n",
       " 'tea': 6,\n",
       " 'remark': 34,\n",
       " 'reckon': 6,\n",
       " 'waistco': 4,\n",
       " 'wool': 2,\n",
       " 'warm': 4,\n",
       " 'wint': 2,\n",
       " 'weath': 10,\n",
       " 'receiv': 21,\n",
       " 'magn': 2,\n",
       " 'word': 123,\n",
       " 'gre': 61,\n",
       " 'aston': 15,\n",
       " 'howev': 31,\n",
       " 'brib': 1,\n",
       " 'wheedl': 1,\n",
       " 'eas': 4,\n",
       " 'steward': 2,\n",
       " 'fight': 3,\n",
       " 'against': 34,\n",
       " 'indign': 5,\n",
       " 'knew': 44,\n",
       " 'weak': 8,\n",
       " 'favo': 11,\n",
       " 'disput': 10,\n",
       " 'end': 78,\n",
       " 'wip': 1,\n",
       " 'perturb': 3,\n",
       " 'regard': 6,\n",
       " 'dread': 18,\n",
       " 'gon': 46,\n",
       " 'away': 64,\n",
       " 'apply': 8,\n",
       " 'remedy': 1,\n",
       " 'cas': 68,\n",
       " 'emerg': 3,\n",
       " 'smok': 10,\n",
       " 'extraordin': 11,\n",
       " 'minut': 23,\n",
       " 'fifty-eight': 1,\n",
       " 'to-day': 10,\n",
       " 'to-morrow': 19,\n",
       " 'hate.': 1,\n",
       " 'clear': 23,\n",
       " 'direct': 38,\n",
       " 'continu': 4,\n",
       " 'farm-bailiff': 1,\n",
       " 'humo': 5,\n",
       " 'sleep': 8,\n",
       " 'night': 60,\n",
       " 'wok': 5,\n",
       " 'house-steward': 1,\n",
       " 'every': 20,\n",
       " 'object': 36,\n",
       " 'least': 10,\n",
       " 'instead': 27,\n",
       " 'self': 5,\n",
       " 'beyond': 13,\n",
       " 'wond': 38,\n",
       " 'wheth': 53,\n",
       " 'gentlem': 53,\n",
       " 'selv': 1,\n",
       " 'subject': 38,\n",
       " 'feel': 50,\n",
       " 'fals': 6,\n",
       " 'wast': 10,\n",
       " 'writing-paper': 1,\n",
       " 'exceiv': 24,\n",
       " 'third': 19,\n",
       " 'quest': 72,\n",
       " 'prop': 12,\n",
       " 'settl': 23,\n",
       " 'scratching': 1,\n",
       " 'head': 77,\n",
       " 'led': 22,\n",
       " 'second': 51,\n",
       " 'consult': 13,\n",
       " 'result': 14,\n",
       " 'regul': 10,\n",
       " 'visit': 13,\n",
       " 'compuls': 1,\n",
       " 'difficul': 20,\n",
       " 'fetch': 17,\n",
       " 'diary': 2,\n",
       " 'answ': 131,\n",
       " 'improv': 8,\n",
       " 'dev': 5,\n",
       " 'observ': 19,\n",
       " 'fierc': 4,\n",
       " 'red': 6,\n",
       " 'journ': 1,\n",
       " 'cre': 17,\n",
       " 'inquir': 17,\n",
       " 'mean': 54,\n",
       " 'fiddlestick': 1,\n",
       " 'sweetheart': 4,\n",
       " 'then': 85,\n",
       " 'plan': 10,\n",
       " 'ment': 44,\n",
       " 'spec': 8,\n",
       " 'cal': 52,\n",
       " 'wednesday': 11,\n",
       " 'sitting-room': 12,\n",
       " 'twenty-fourth': 1,\n",
       " 'forty-eight': 1,\n",
       " 'surpr': 26,\n",
       " 'abroad': 6,\n",
       " 'stay': 7,\n",
       " 'london': 52,\n",
       " 'stop': 50,\n",
       " 'mon': 3,\n",
       " 'birthday.': 3,\n",
       " 'hat': 17,\n",
       " 'prev': 10,\n",
       " 'throwing': 2,\n",
       " 'ceil': 1,\n",
       " 'boy': 48,\n",
       " 'along': 21,\n",
       " 'sight': 16,\n",
       " 'nicest': 1,\n",
       " 'spun': 1,\n",
       " 'top': 13,\n",
       " 'brok': 11,\n",
       " 'window': 31,\n",
       " 'whom': 22,\n",
       " 'return': 46,\n",
       " 'atrocy': 1,\n",
       " 'tyr': 1,\n",
       " 'tort': 3,\n",
       " 'dol': 2,\n",
       " 'hardest': 3,\n",
       " 'driv': 16,\n",
       " 'exhaust': 1,\n",
       " 'string': 2,\n",
       " 'har': 2,\n",
       " 'burn': 5,\n",
       " 'ach': 2,\n",
       " 'fatigu': 1,\n",
       " 'sum': 20,\n",
       " 'blake.': 3,\n",
       " 'nat': 35,\n",
       " 'country': 12,\n",
       " 'becaus': 21,\n",
       " 'misfortun': 6,\n",
       " 'heir': 1,\n",
       " 'dukedom': 3,\n",
       " 'prov': 31,\n",
       " 'eldest': 3,\n",
       " 'celebr': 9,\n",
       " 'blake–equally': 1,\n",
       " 'fam': 6,\n",
       " 'rich': 4,\n",
       " 'suit': 4,\n",
       " 'many': 31,\n",
       " 'worry': 4,\n",
       " 'tribun': 2,\n",
       " 'duk': 5,\n",
       " 'himself': 84,\n",
       " 'place–how': 1,\n",
       " 'purs': 1,\n",
       " 'fil': 3,\n",
       " 'otherw': 7,\n",
       " 'harmless': 3,\n",
       " 'ear': 26,\n",
       " 'wrong–is': 1,\n",
       " 'deal': 14,\n",
       " 'childr': 6,\n",
       " 'door': 80,\n",
       " 'money': 27,\n",
       " 'tre': 27,\n",
       " 'educ': 6,\n",
       " 'institut': 7,\n",
       " 'behav': 4,\n",
       " 'ad': 29,\n",
       " 'dislik': 1,\n",
       " 'includ': 5,\n",
       " 'admit': 14,\n",
       " 'mast': 8,\n",
       " 'supery': 9,\n",
       " 'germany': 3,\n",
       " 'remain': 27,\n",
       " 'snug': 3,\n",
       " 'fellow-countrymen': 1,\n",
       " 'parlia': 4,\n",
       " 'publ': 7,\n",
       " 'unfin': 1,\n",
       " 'neith': 14,\n",
       " 'nor': 19,\n",
       " 'troubl': 25,\n",
       " 'seny': 2,\n",
       " 'leav': 76,\n",
       " 'stick': 7,\n",
       " 'bring': 22,\n",
       " 'unlucky': 8,\n",
       " 'jewel': 28,\n",
       " 'nic': 18,\n",
       " 'forget': 13,\n",
       " 'wrot': 7,\n",
       " 'sometim': 18,\n",
       " 'transact': 1,\n",
       " 'consist': 3,\n",
       " 'borrow': 3,\n",
       " 'bal': 7,\n",
       " 'four-bladed': 1,\n",
       " 'knif': 1,\n",
       " 'seven-and-sixpence': 2,\n",
       " 'money–the': 1,\n",
       " 'colo': 15,\n",
       " 'chief': 16,\n",
       " 'learnt': 1,\n",
       " 'teach': 1,\n",
       " 'french': 8,\n",
       " 'univers': 5,\n",
       " 'geni': 3,\n",
       " 'paint': 27,\n",
       " 'sang': 1,\n",
       " 'play': 6,\n",
       " 'compos': 15,\n",
       " 'little–borrowing': 1,\n",
       " 'suspect': 40,\n",
       " 'moth': 26,\n",
       " 'fortun': 5,\n",
       " 'sev': 10,\n",
       " 'ran': 8,\n",
       " 'siev': 1,\n",
       " 'hol': 17,\n",
       " 'pocket': 16,\n",
       " 'sew': 1,\n",
       " 'wherev': 3,\n",
       " 'welcom': 8,\n",
       " 'everywh': 2,\n",
       " 'address': 28,\n",
       " 'post': 8,\n",
       " 'europe–to': 1,\n",
       " 'for.': 1,\n",
       " 'twic': 7,\n",
       " 'sav': 15,\n",
       " 'un': 4,\n",
       " 'stood': 36,\n",
       " 'attempt': 11,\n",
       " 'success': 5,\n",
       " 'thursday': 16,\n",
       " 'twenty-fifth': 2,\n",
       " 'grown': 2,\n",
       " 'blood': 2,\n",
       " 'cour': 3,\n",
       " 'five-and-twenty': 3,\n",
       " 'did–before': 1,\n",
       " 'fin': 19,\n",
       " 'dinner-time': 2,\n",
       " 'drov': 10,\n",
       " 'lunch': 2,\n",
       " 'neighbo': 7,\n",
       " 'bedroom': 10,\n",
       " 'ready': 23,\n",
       " 'guest': 10,\n",
       " 'straight': 21,\n",
       " 'butl': 1,\n",
       " 'request': 14,\n",
       " 'vex': 5,\n",
       " 'anybody': 17,\n",
       " 'key': 13,\n",
       " 'cell': 1,\n",
       " '–then': 1,\n",
       " 'lato': 1,\n",
       " 'claret': 2,\n",
       " 'air': 15,\n",
       " 'chil': 3,\n",
       " 'din': 34,\n",
       " 'conclud': 22,\n",
       " 'next–seeing': 1,\n",
       " 'eq': 12,\n",
       " 'age–i': 1,\n",
       " 'beeh': 3,\n",
       " 'chair': 15,\n",
       " 'court': 7,\n",
       " 'sound': 9,\n",
       " 'soft': 14,\n",
       " 'beat': 2,\n",
       " 'drum': 2,\n",
       " 'terrac': 20,\n",
       " 'front': 9,\n",
       " 'resid': 3,\n",
       " 'going': 65,\n",
       " 'mahogany-coloured': 1,\n",
       " 'whit': 19,\n",
       " 'frock': 1,\n",
       " 'trous': 1,\n",
       " 'hand-drums': 1,\n",
       " 'slung': 1,\n",
       " 'behind': 26,\n",
       " 'delicate-looking': 1,\n",
       " 'light-haired': 1,\n",
       " 'engl': 30,\n",
       " 'carry': 27,\n",
       " 'bag': 3,\n",
       " 'fellow': 5,\n",
       " 'strolling': 4,\n",
       " 'cond': 1,\n",
       " 'tool': 1,\n",
       " 'trad': 2,\n",
       " 'exhibit': 5,\n",
       " 'eleg': 3,\n",
       " 'permit': 10,\n",
       " 'trick': 5,\n",
       " 'sour': 4,\n",
       " 'gen': 21,\n",
       " 'amus': 8,\n",
       " 'distrust': 3,\n",
       " 'few': 17,\n",
       " 'shad': 3,\n",
       " 'dark': 19,\n",
       " 'weaknesses–and': 1,\n",
       " 'plate-basket': 2,\n",
       " 'pantry-table': 1,\n",
       " 'inst': 28,\n",
       " 'remind': 15,\n",
       " 'basket': 2,\n",
       " 'stranger': 8,\n",
       " 'whos': 15,\n",
       " 'party': 6,\n",
       " 'prem': 7,\n",
       " 'bow': 6,\n",
       " 'sunny': 2,\n",
       " 'exact': 7,\n",
       " 'rous': 8,\n",
       " 'run': 16,\n",
       " 'fir': 14,\n",
       " 'juggl': 29,\n",
       " 'meant': 23,\n",
       " 'mischief': 12,\n",
       " 'explain': 20,\n",
       " 'appear': 60,\n",
       " 'lodg': 7,\n",
       " 'gossip': 2,\n",
       " 'lodge-keeper': 1,\n",
       " 'ill-used': 3,\n",
       " 'foreigners–for': 1,\n",
       " 'delicate-looking–th': 1,\n",
       " 'stol': 16,\n",
       " 'hedg': 2,\n",
       " 'road': 13,\n",
       " 'watch': 12,\n",
       " 'foreign': 20,\n",
       " 'star': 12,\n",
       " 'jab': 1,\n",
       " 'help': 51,\n",
       " 'hold': 26,\n",
       " 'hand.': 2,\n",
       " 'heart': 29,\n",
       " 'fly': 6,\n",
       " 'flesh': 5,\n",
       " 'creep.': 1,\n",
       " 'ben': 4,\n",
       " 'comply': 8,\n",
       " 'shrunk': 1,\n",
       " 'shook': 12,\n",
       " 'thereupon': 9,\n",
       " 'unkind': 3,\n",
       " 'empty': 14,\n",
       " 'market–a': 1,\n",
       " 'hungry': 1,\n",
       " 'rag': 5,\n",
       " 'forsak': 1,\n",
       " 'chap': 1,\n",
       " 'unwil': 5,\n",
       " 'bottl': 8,\n",
       " 'bosom': 5,\n",
       " 'pour': 9,\n",
       " 'black': 11,\n",
       " 'stuff': 3,\n",
       " 'ink': 13,\n",
       " 'palm': 3,\n",
       " 'indian–first': 1,\n",
       " 'touch': 11,\n",
       " 'sign': 24,\n",
       " 'air–then': 1,\n",
       " 'look.': 1,\n",
       " 'becam': 7,\n",
       " 'stiff': 2,\n",
       " 'statu': 2,\n",
       " 'hollow': 1,\n",
       " 'accompany': 5,\n",
       " ...}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betteredgeStemsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "betteredgeSents = nltk.sent_tokenize(betteredge)\n",
    "clackSents = nltk.sent_tokenize(clack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' \\n\\n### Chapter I\\n\\nI am indebted to my dear parents (both now in heaven) for having had\\nhabits of order and regularity instilled into me at a very early age.',\n",
       " 'In that happy bygone time, I was taught to keep my hair tidy at all\\nhours of the day and night, and to fold up every article of my clothing\\ncarefully, in the same order, on the same chair, in the same place at\\nthe foot of the bed, before retiring to rest.',\n",
       " 'An entry of the day’s\\nevents in my little diary invariably preceded the folding up.',\n",
       " 'The\\n“Evening Hymn” (repeated in bed) invariably followed the folding up.',\n",
       " 'And the sweet sleep of childhood invariably followed the “Evening Hymn.”\\n\\nIn later life (alas!)']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clackSents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "100\n",
      "279\n",
      "80\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "for sent in betteredgeSents[100:105]: \n",
    "    print(len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "clackSentenceLengths = []\n",
    "for sent in clackSents: \n",
    "    clackSentenceLengths.append(len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "betteredgeSentenceLengths = []\n",
    "for sent in betteredgeSents: \n",
    "    betteredgeSentenceLengths.append(len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.87649164677805"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(clackSentenceLengths)/len(clackSentenceLengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112.04363827549948"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(betteredgeSentenceLengths)/len(betteredgeSentenceLengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "clackCounts = Counter(clackStems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "betteredgeCounts = Counter(betteredgeStems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([clackCounts, betteredgeCounts], index=[\"Clack\", \"Betteredge\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clackness'] = df['Clack'] - df['Betteredge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clack</th>\n",
       "      <th>Betteredge</th>\n",
       "      <th>Clackness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aunt</th>\n",
       "      <td>103.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>godfrey</th>\n",
       "      <td>124.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dear</th>\n",
       "      <td>90.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ablewhit</th>\n",
       "      <td>82.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bruff</th>\n",
       "      <td>57.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clack</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luk</th>\n",
       "      <td>41.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marry</th>\n",
       "      <td>37.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precy</th>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>33.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christian</th>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friend</th>\n",
       "      <td>53.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interf</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moth</th>\n",
       "      <td>40.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>son</th>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publ</th>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <td>27.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squ</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>street</th>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ton</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dearest</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>libr</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diary</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nar</th>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>few</th>\n",
       "      <td>25.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stamp</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yours.</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yourself–</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yourself–and</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you–i</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you–if</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you–which</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–all</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–farewell</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–had</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–he</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–if</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–lights</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–my</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–not</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–on</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–persons</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–that</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–the</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–then</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–they</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–this</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–those</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–we</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–what</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–who</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–with</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–writes</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–you</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5262 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Clack  Betteredge  Clackness\n",
       "aunt          103.0        28.0       75.0\n",
       "godfrey       124.0        52.0       72.0\n",
       "dear           90.0        21.0       69.0\n",
       "ablewhit       82.0        20.0       62.0\n",
       "bruff          57.0         8.0       49.0\n",
       "clack          50.0         3.0       47.0\n",
       "luk            41.0         7.0       34.0\n",
       "marry          37.0        14.0       23.0\n",
       "precy          24.0         3.0       21.0\n",
       "oh             33.0        13.0       20.0\n",
       "christian      26.0         6.0       20.0\n",
       "friend         53.0        38.0       15.0\n",
       "interf         15.0         1.0       14.0\n",
       "moth           40.0        26.0       14.0\n",
       "son            21.0         9.0       12.0\n",
       "eng            18.0         6.0       12.0\n",
       "publ           19.0         7.0       12.0\n",
       "book           27.0        16.0       11.0\n",
       "squ            13.0         2.0       11.0\n",
       "street         13.0         3.0       10.0\n",
       "ton            12.0         2.0       10.0\n",
       "dearest        10.0         1.0        9.0\n",
       "libr           17.0         8.0        9.0\n",
       "diary          11.0         2.0        9.0\n",
       "nar            14.0         5.0        9.0\n",
       "few            25.0        17.0        8.0\n",
       "prep           12.0         4.0        8.0\n",
       "stamp           9.0         1.0        8.0\n",
       "fold           11.0         3.0        8.0\n",
       "insult         12.0         4.0        8.0\n",
       "...             ...         ...        ...\n",
       "yours.          2.0         NaN        NaN\n",
       "yourself–       NaN         1.0        NaN\n",
       "yourself–and    NaN         1.0        NaN\n",
       "youth           1.0         NaN        NaN\n",
       "you–i           1.0         NaN        NaN\n",
       "you–if          NaN         1.0        NaN\n",
       "you–which       NaN         1.0        NaN\n",
       "–               NaN         2.0        NaN\n",
       "–all            NaN         1.0        NaN\n",
       "–farewell       NaN         1.0        NaN\n",
       "–had            NaN         1.0        NaN\n",
       "–he             NaN         1.0        NaN\n",
       "–if             1.0         NaN        NaN\n",
       "–lights         NaN         1.0        NaN\n",
       "–my             NaN         1.0        NaN\n",
       "–not            1.0         NaN        NaN\n",
       "–on             1.0         NaN        NaN\n",
       "–persons        NaN         1.0        NaN\n",
       "–that           1.0         NaN        NaN\n",
       "–the            NaN         1.0        NaN\n",
       "–then           NaN         1.0        NaN\n",
       "–they           NaN         1.0        NaN\n",
       "–this           NaN         1.0        NaN\n",
       "–those          1.0         NaN        NaN\n",
       "–we             NaN         1.0        NaN\n",
       "–what           NaN         1.0        NaN\n",
       "–who            NaN         1.0        NaN\n",
       "–with           1.0         NaN        NaN\n",
       "–writes         1.0         NaN        NaN\n",
       "–you            NaN         1.0        NaN\n",
       "\n",
       "[5262 rows x 3 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='Clackness', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
