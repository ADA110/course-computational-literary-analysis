{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text\n",
    "\n",
    "Generating text can be done by mimicing the probabilities of words following other words. Let's try it with \"The Garden Party.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenParty = open('../Texts/garden-party.md').read().split('\\n# ')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2. THE GARDEN PARTY.\\n\\nAnd afte'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gardenParty[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from random import choice\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll build a dictionary, where each type (i.e. word) will be a key, and the value will be a list of words that follow that word. For example, in the sentence, \"the quick brown fox jumped over the lazy dogs,\" that dictionary would look like: \n",
    "\n",
    "```python\n",
    "{\"the\": [\"quick\", \"lazy\"],\n",
    " \"quick\": [\"brown\"],\n",
    " \"fox\": [\"jumped\"],\n",
    " \"over\": [\"the\"],\n",
    " \"lazy\": [\"dogs\"],\n",
    " \"dogs\": [\".\"]}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenDoc = nlp(gardenParty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenDist = {}\n",
    "for word in gardenDoc[:-1]:\n",
    "    nextWord = gardenDoc[word.i + 1].text\n",
    "    wordText = word.text\n",
    "    if wordText not in gardenDist: \n",
    "        gardenDist[wordText] = [nextWord]\n",
    "    else: \n",
    "        gardenDist[wordText].append(nextWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all', 'the', 'breakfast', 'the', 'all', 'that', '\\n']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gardenDist['after']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to start the Markov chain, choose a random word from the dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = choice(list(gardenDist.keys()))\n",
    "seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then choose the next word from among those that follow it. Repeat this, using that following word as your new seed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = [seed]\n",
    "for i in range(50):     \n",
    "    if seed in gardenDist: \n",
    "        nextWord = choice(gardenDist[seed])\n",
    "        seed = nextWord\n",
    "        chain.append(nextWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sing', 'this', 'year', '.', 'The', 'very', 'nice', 'men', '.', 'There', 'on', 'a', 'small', '.', 'The', 'door', ',', 'can', 'we', 'ca', \"n't\", 'you', 'would', 'be', '.', '\"', 'If', 'you', 'come', '.', '\"', 'I', '---', 'is', \"n't\", '\\n', 'turned', 'round', 'her', 'through', '.', '\"', 'Of', 'course', ',', 'sick', 'hens', 'and', 'even', 'a', 'fright']\n"
     ]
    }
   ],
   "source": [
    "print(chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean it up with some quick-and-dirty detokenizing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing this year . The very nice men . There on a small . The door , can we ca n\\'t you would be . \" If you come . \" I --- is n\\'t  turned round her through . \" Of course , sick hens and even a fright'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(chain).replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
